{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "# Multilayer perceptrons\n",
    "class MLP(nn.Block):\n",
    "    # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "    def __init__(self, **kwargs):\n",
    "        # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "        # 参数，如“模型参数的访问、初始化和共享”一节将介绍的模型参数params\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Dense(256, activation='relu')  # 隐藏层\n",
    "        self.output = nn.Dense(10)  # 输出层\n",
    "\n",
    "    # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "    # MLP类中无须定义反向传播函数。系统将通过自动求梯度而自动生成反向传播所需的backward函数。\n",
    "    def forward(self, x):\n",
    "        return self.output(self.hidden(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.00711333  0.00847135  0.00836362  0.00435072  0.01855784 -0.01614245\n",
       "  -0.03962736  0.03282262 -0.01430595  0.12822872]\n",
       " [-0.00122278  0.03290728  0.04022461 -0.00938234  0.0041625  -0.05285572\n",
       "  -0.04280645  0.04432166  0.01938271  0.11949807]]\n",
       "<NDArray 2x10 @gpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.random.uniform(shape=(2, 20),ctx=mx.gpu())\n",
    "net = MLP()\n",
    "net.initialize(ctx=mx.gpu())\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block类是一个通用的部件。事实上，Sequential类继承自Block类\n",
    "class MySequential(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MySequential, self).__init__(**kwargs)\n",
    "\n",
    "    def add(self, block):\n",
    "        # block是一个Block子类实例，假设它有一个独一无二的名字。我们将它保存在Block类的\n",
    "        # 成员变量_children里，其类型是OrderedDict。当MySequential实例调用\n",
    "        # initialize函数时，系统会自动对_children里所有成员初始化\n",
    "        self._children[block.name] = block\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Collection.OrderedDict()保证会按照成员添加时的顺序遍历成员\n",
    "        for block in self._children.values():\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.0356168  -0.0654178  -0.0182656  -0.03344025 -0.02687218  0.01729953\n",
       "  -0.07620525 -0.02019735 -0.01474128  0.03277251]\n",
       " [ 0.07830474 -0.0699421  -0.04908896 -0.05017216  0.02884687 -0.04290424\n",
       "  -0.02280661 -0.03931685 -0.00523395  0.05043975]]\n",
       "<NDArray 2x10 @gpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential()\n",
    "net.add(nn.Dense(256, activation='relu'))\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize(ctx=mx.gpu())\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "class FancyMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FancyMLP, self).__init__(**kwargs)\n",
    "        # 使用get_constant创建的随机权重参数不会在训练中被迭代（即常数参数）\n",
    "        self.rand_weight = self.params.get_constant(\n",
    "            'rand_weight', nd.random.uniform(shape=(20, 20)))\n",
    "        self.dense = nn.Dense(20, activation='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        # 使用创建的常数参数，以及NDArray的relu函数和dot函数\n",
    "        x = nd.relu(nd.dot(x, self.rand_weight.data()) + 1)\n",
    "        # 复用全连接层。等价于两个全连接层共享参数\n",
    "        x = self.dense(x)\n",
    "        # 控制流，这里我们需要调用asscalar函数来返回标量进行比较\n",
    "        while x.norm().asscalar() > 1:\n",
    "            x /= 2\n",
    "        if x.norm().asscalar() < 0.8:\n",
    "            x *= 10\n",
    "        return x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.3848565]\n",
      "<NDArray 1 @gpu(0)> 1.3848565\n",
      "\n",
      "[0.]\n",
      "<NDArray 1 @gpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[29.943895]\n",
       "<NDArray 1 @gpu(0)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FancyMLP()\n",
    "net.initialize(ctx=mx.gpu())\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.86603445]\n",
      "<NDArray 1 @gpu(0)> 0.86603445\n",
      "\n",
      "[0.]\n",
      "<NDArray 1 @gpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[2.9067159]\n",
       "<NDArray 1 @gpu(0)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Block):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NestMLP, self).__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add(nn.Dense(64, activation='relu'),\n",
    "                     nn.Dense(32, activation='relu'))\n",
    "        self.dense = nn.Dense(16, activation='relu')\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(self.net(x))\n",
    "    \n",
    "\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(NestMLP(), nn.Dense(20), FancyMLP())\n",
    "\n",
    "net.initialize(ctx=mx.gpu())\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
