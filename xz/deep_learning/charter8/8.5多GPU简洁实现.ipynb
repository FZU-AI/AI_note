{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn, utils as gutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(num_classes):  # 本函数已保存在d2lzh包中方便以后使用\n",
    "    def resnet_block(num_channels, num_residuals, first_block=False):\n",
    "        blk = nn.Sequential()\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.add(d2l.Residual(\n",
    "                    num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.add(d2l.Residual(num_channels))\n",
    "        return blk\n",
    "\n",
    "    net = nn.Sequential()\n",
    "    # 这里使用了较小的卷积核、步幅和填充，并去掉了最大池化层\n",
    "    net.add(nn.Conv2D(64, kernel_size=3, strides=1, padding=1),\n",
    "            nn.BatchNorm(), nn.Activation('relu'))\n",
    "    net.add(resnet_block(64, 2, first_block=True),\n",
    "            resnet_block(128, 2),\n",
    "            resnet_block(256, 2),\n",
    "            resnet_block(512, 2))\n",
    "    net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))\n",
    "    return net\n",
    "\n",
    "net = resnet18(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = [mx.gpu(0),mx.cpu(0)]\n",
    "net.initialize(init=init.Normal(sigma=0.01),force_reinit=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[ 1.0006834e-06  6.7762932e-07  4.8034249e-06 -2.0505538e-06\n",
       "    3.6689387e-06  1.2511016e-06 -2.1064225e-06 -1.3070419e-06\n",
       "    2.8637310e-06  3.2923047e-06]\n",
       "  [ 7.4181497e-07  2.6879442e-07  4.6454452e-06 -1.8912955e-06\n",
       "    3.9271749e-06  1.4061950e-06 -2.5943013e-06 -1.3177248e-06\n",
       "    2.4489993e-06  3.5721191e-06]]\n",
       " <NDArray 2x10 @gpu(0)>,\n",
       " \n",
       " [[ 5.4366717e-07  6.8477402e-07  4.1176017e-06 -1.5228464e-06\n",
       "    3.2764810e-06  1.4188942e-06 -1.6311110e-06 -1.1858672e-06\n",
       "    2.1414864e-06  3.7148905e-06]\n",
       "  [ 7.2043127e-07  8.3965318e-07  3.6648519e-06 -1.5985751e-06\n",
       "    3.2497187e-06  7.2354050e-07 -1.9599513e-06 -1.0965462e-06\n",
       "    2.6601374e-06  3.6148099e-06]]\n",
       " <NDArray 2x10 @cpu(0)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.random.uniform(shape=(4, 1, 28, 28))\n",
    "cpu_gpu_x = gutils.split_and_load(x, ctx)\n",
    "net(cpu_gpu_x[0]),net(cpu_gpu_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[-0.00227942  0.00201315  0.00350055]\n",
       "  [ 0.00536052  0.01519444  0.01904088]\n",
       "  [-0.01573443 -0.00140079  0.00296701]]]\n",
       "<NDArray 1x3x3 @gpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = net[0].params.get('weight')\n",
    "\n",
    "# 默认情况下weight.data()会返回内存上的参数值。\n",
    "try:\n",
    "    weight.data()\n",
    "except RuntimeError:\n",
    "    print('not initialized on', mx.cpu())\n",
    "weight.data(ctx[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ctx, batch_size, lr):\n",
    "    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "    print('running on:', ctx)\n",
    "    net.initialize(init=init.Normal(sigma=0.01), ctx=ctx, force_reinit=True)\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    for epoch in range(4):\n",
    "        start = time.time()\n",
    "        for X, y in train_iter:\n",
    "            gpu_Xs = gutils.split_and_load(X, ctx)\n",
    "            gpu_ys = gutils.split_and_load(y, ctx)\n",
    "            with autograd.record():\n",
    "                ls = [loss(net(gpu_X), gpu_y)\n",
    "                      for gpu_X, gpu_y in zip(gpu_Xs, gpu_ys)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "        nd.waitall()\n",
    "        train_time = time.time() - start\n",
    "        test_acc = d2l.evaluate_accuracy(test_iter, net, ctx[0])\n",
    "        print('epoch %d, time %.1f sec, test acc %.2f' % (\n",
    "            epoch + 1, train_time, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: [gpu(0), cpu(0)]\n"
     ]
    }
   ],
   "source": [
    "train(ctx, batch_size=256, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
