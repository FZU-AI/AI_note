---
typora-root-url: picture
typora-copy-images-to: picture
---

# 第五章 卷积神经网络

它是计算机视觉领域取得突破性进展的基石。也逐渐被应用在自然语言处理，推荐系统和语音识别等领域。本章主要介绍卷积网络中的卷积层和池化层工作原理，并解释填充，步幅，输入通道和输出通道的含义。

## 二维卷积层

卷积神经网络是含有卷积层的神经网络，它有高和宽两个空间维度，常用来处理图像数据。

**二维互相关运算** 在二维卷积层中，一个二维输入和一个二维核数据通过互相关运算输出一个二维数组。如下图，输入是一个高和宽都为3的二维数组，核数组的宽和高都为2，该数组在卷积计算中有称为卷积核或过滤器。卷积核窗口(卷积窗口)的形状取决于卷积核的高和宽。计算如下所示，应用部分为第一个输出元素所使用的输入和核数组元素:0 ×0+1 ×1+3 ×2+4×3=19。其运算封装成了corr2d(X,K)函数，返回卷积窗口。

![5_1](/5_1.png)

二维卷积层将输入和卷积核做互相关运算，再加上一个标量偏差来得到输出。其参数为卷积核和偏差。在训练时，先随机初始化，然后不断迭代卷积核和偏差。二维互相关计算和自定义的二维卷积层如下:

```python
def corr2d(X,K):
    h,w = K.shape
    Y=nd.zeros((X.shape[0]-h+1,X.shape[1]-w+1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i,j] = (X[i:i+h,j:j+w]*K).sum()
    return Y

class Conv2D(nn.Block):
    def __init__(self,kernel_size,**kwargs):
        super(Conv2D,self).__init__(**kwargs)
        self.weight = self.params.get('weight',shape=kernel_size)
        self.bias = self.params.get('bias',shape=(1,))

    def forward(self,X):
        return corr2d(X,self.weight().data)+self.bias.data()

```

**图像中物体边缘检测** 使用卷积层可以检测图片中物体的边缘，对于中间4列为黑(0),其余为白(1)的6*8的图像，通过[1,-1]的卷积核，可以便是出当横向相邻元素相同时会输出0，否则输出非0，计算后可以看出黑白之间的边缘都变成了1或-1。由此可以知道，卷积层可以通过重复使用卷积核有效的表征局部空间。

**通过数据学习核数组** 通过数据数据X和输出数据Y来学习构造核数组K。首先随机初始化卷积核，接下来在每一次迭代中，使用平方误差来比较Y和卷积层的输出，然后计算梯度来更新权重。由于coo2d中使用了对 单个元素[i,j]的操作，无法自动求梯度，使用Gluon提供的Conv2D来实现。

```python
X = nd.ones((6, 8))
X[:, 2:6] = 0
K = nd.array([[1, -1]])
Y = corr2d(X, K)

#构造⼀个输出通道数为1，核数组形状是(1, 2)的⼆维卷积层
conv2d = nn.Conv2D(1, kernel_size=(1, 2))
conv2d.initialize()

# ⼆维卷积层使⽤4维输⼊输出，格式为(样本, 通道, ⾼, 宽)，这⾥批量⼤⼩（批量中的样本数）和通道数均为1
X = X.reshape((1,1,6,8))
Y = Y.reshape((1,1,6,7))

for i in range(10):
    with autograd.record():
        Y_hat = conv2d(X)
        l = (Y_hat - Y)**2
    l.backward()
    conv2d.weight.data()[:] -= 3e-2 * conv2d.weight.grad()
```

**互相关运算和卷积运算** 卷积运算和互相关运算类似，卷积运算只需要将核数组左右翻转并上下翻转，在与输入数组做互相关运算。卷积层能使用互相关运算代替卷积运算。

**特征图和感受野** 二维卷积层的输出可以看做时输入在空间维度上某以及的表征，也叫做特征图。对于影响输出元素x计算的输入区域，叫做x的感受野。如上图形状为2×2的输出记为Y，在一个更深层的卷积神经网络中，将Y于另一个核数组做相关运算，得到的元素z的感受野在X上就是3×3区域的9个元素。因此通过更深层的神经网络是特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。在神经网络中这些元素也可称为“单元”。

## 填充和步幅

填充和步幅是两个超参数，他们可以对给定形状的输入和卷积核改变输出形状。

**填充** 指在输入高和宽的两侧天聪元素(通常是0)，如下图在原输入高和宽的两侧添加了0，使得高和宽边为了5。

![5_2](/5_2.png)

记填充的行数为p_h,填充的列数p_w；k_h和k_w指核的高和宽，通常我们我们会设置p_h=k_h-1,p_w=k_w-1，使得输入和输出具有相同的高和宽。这样会方便在构造网络时推测每个层的输出形状。当核的函数和列数为奇数时，左右和上下可以平均填充，为偶数时，会在左边，上面多填充一行(列)。

**步幅** 在⼆维互相关运算中，卷积窗口从输⼊数组的最左上⽅开始，按从左往右、从上往下的顺序，依次在输⼊数组上滑动。我们将每次滑动的⾏数和列数称为步幅。设置在⾼上步幅为3、在宽上步幅为2的⼆维互相关运算。以看到，输出第⼀列第⼆个元素时，卷积窗口向下滑动了3⾏，而在输出第⼀⾏第⼆个元素时卷积窗口向右滑动了2列。当卷积窗口在输⼊上再向右滑动2列时，由于输⼊元素⽆法填满窗口，⽆结果输出。

![5_3](/5_3.png)

`conv2d = nn.Conv2D(1, kernel_size=(3, 5), padding=(0, 1), strides=(3, 4))`表示卷积级窗口大小为3*5，上下左右填充1行(列)，行步幅为3，列步幅为4。默认情况步幅为1。

## 多输入通道和多输出通道

真实的数据维度经常是超过二维的。例如，彩⾊图像在⾼和宽2个维度外还有RGB（红绿蓝）3个颜⾊通道。假设彩⾊图像的⾼和宽分别是h和w(像素),那么它可以表⽰为⼀个3×h×w的多维数组。将大小为3的这一维称为通道维。

**多输入通道** 当输⼊数据含多个通道时，我们需要构造⼀个输⼊通道数与输⼊数据的通道数相同的卷积核，从而能够与含多通道的输⼊数据做互相关运算。当通道数大于1时，会为每一个通道分配一个大小相同的二维卷积核，在进行互相关运算，然后将各个通道上的结果相加，最后得到一个二维数组。实现含多个输⼊通道的互相关运算，只需要对每个通道做互相关运算，然后通过add_n函数来进⾏累加。

```python
def corr2d_multi_in(X, K):
# ⾸先沿着X和K的第0维（通道维）遍历。然后使⽤*将结果列表变成add_n函数的位置参数
# （positional argument）来进⾏相加
    return nd.add_n(*[d2l.corr2d(x, k) for x, k in zip(X, K)])
```

**多输出通道** 当输⼊通道有多个时，在使用累加时，输出通道数总是1。卷积核输⼊通道数和输出通道数分别为c_i 和c_o ,如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为c_i × k_h × k_w 的核数组。卷积核的形状即c_o × c_i × k_h × k_w。每个输出通道的结果由卷积核在该输出通道上的核数组与输入数组计算而来。

```python
def corr2d_multi_in_out(X, K):
    # 对K的第0维遍历，每次同输⼊X做互相关计算。所有结果使⽤stack函数合并在⼀起
    return nd.stack(*[corr2d_multi_in(X, k) for k in K])

```

**1 × 1卷积层** 指卷积窗口形状为1 × 1的多通道卷积层。其诗句了识别高和宽上相邻元素构成的模式和功能。1 × 1卷积的主要计算发⽣在通道维上，我们将通道维当作特征维，将⾼和宽维度上的元素当成数据样本，那么1 × 1卷积层的作⽤与全连接层等价。

```python
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape
    c_o = K.shape[0]
    X = X.reshape((c_i, h * w))
    K = K.reshape((c_o, c_i))
    Y = nd.dot(K, X) # 全连接层的矩阵乘法
    return Y.reshape((c_o, h, w))
    
X = nd.random.uniform(shape=(3, 3, 3))
K = nd.random.uniform(shape=(2, 3, 1, 1))
```

## 池化层

由于要识别的物体不会总出现在图片上的固定位置，这会导致同⼀个边缘对应的输出可能出现在卷积输出Y中的不同位置，进而对后⾯的模式识别造成不便。通过池化层可以缓解卷积层对位置的过度敏感。

**二维最大池化层和平均池化层** 池化层有一个赤化窗口，池化窗口从输入数组的滑动(与卷积窗口类似)，输出窗口中输入子数组的最大值或平均值作为相应位置的输出元素。最大池化层的示例如下。

![5_4](/5_4.png)

在之前的物体边缘检测的例子中，设该卷积层输⼊是X、池化层输出为Y。⽆论是X[i, j]和X[i, j+1]值不同，还是X[i, j+1]和X[i, j+2]不同，池化层输出均有Y[i, j]=1。也就是说，使⽤2×2最⼤池化层时，只要卷积层识别的模式在⾼和宽上移动不超过⼀个元素，我们依然可以将它检测出来。

**填充和步幅** 同卷积层类似，池化层也有填充和步幅，其工作机制和卷积层类似。一下演示nn模块中的MaxPool2D的填充和步幅的工作机制。输入的前两维时批量和通道。

```python
pool2d = nn.MaxPool2D(3)   #使用(3,3)的池化窗口，默认获得(3,3)的步幅
pool2d = nn.MaxPool2D(3, padding=1, strides=2)  #手动指定填充和步幅
pool2d = nn.MaxPool2D((2, 3), padding=(1, 2), strides=(2, 3))   #指定非正方形的填充和步幅
```

**多通道** 池化层对每个输⼊通道分别池化，不同于卷积层将各个通道的输出相加，其输出通道数等于输入通道数。

## 卷积神经网络(LeNet)

在多层感知机中，其分类算法有一定的局限性。一、在同一列临近的像素在这个向来中可能相距较远。他们构成的模型很难别识别。二、对于较大尺寸的输入图像，使用全连接层容易导致模型过大。如高宽均为1000像素的彩色图像(RGB三个通道)。即使全连接层的输出仍是256，他的参数形状为3000000*256，占用约3GB的内存或显存。

卷积层尝试解决了这两个问题，一是卷积层保留输入形状，图像在高宽上的相关性有可能被有效识别，二是卷积层使用同一卷积核与不同位置的输入重复计算，避免了参数过大。

**LeNet模型** LeNet指用来识别手写数字图像的卷积神经网络。LeNet分为卷积层块和全连接层块两个部分。卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式(线条，物体局部)，最大池化层用来减低卷积层对位置的敏感性。卷积层块有两个这样的基本单位重复堆叠构成。每个卷积层都使用5\*5的窗口，并在输出上使用sigmoid激活函数。第一个卷积层的诶输出通道为6，由于第二个卷积层输入的高宽要更小，第二个卷积层的输出通道增加到16，使两个卷积层的参数尺寸类似。都使用了形状为2\*2的最大池化层，步幅为2。

卷积层块的输出形状为(批量⼤小, 通道, ⾼, 宽)，再传入全连接层块。全连接层会将小批量中的每个样本变平。其输入形状变为2维，第一位是小批量中的样本，第二维时样本变平后的向量表示。向量长度为：通道\*高\*宽。全连接块有3个全连接层。输出个数分别为120,84,10。其中10为输出类别数。

## 深度卷积神经网络(AlexNet)

神经网络可以直接基于图像的原始像素进行分类，称为端到端的方法可以节省很多中间步骤。但是在过去很长一段时间里，主要依靠研究者设计生成的手工特征。其图像分类的主要流程是:1.获取图像数据集；2.使用已有的特征提取函数生成图像的特征；3.使用机器学习模型对图像的特征分类。当时认为机器学习的部分仅在最后一步。然后使用较干净的数据和较有效的数据甚至比机器学习模型的选择的影响更大。

**学习特征** 一些研究者认为不因使用特征提取函数来提取特征，而是通过学习来获得特征。认为多层神经网络可能可以学得数据的多级表征，并逐级表示越来越抽象的概念或模式。当是其有两个确实要素。一是数据。包含许多特征的深度学习模型需要大量的有标签的数据才能比其他经典方法好。限于早期有限的存储和研究预算，大部分研究只基于小的公开数据集。从2009年诞生的ImageNet数据集开始有巨大的改善，它包含了1000大类物体，没类哟uduoda数千张不同的图像，从此传统的方法不再有优势。二是硬件。早起的硬件计算能力有限，使训练较复杂的神经网络很困难。从OpenCL和CUDA之类的编程框架开始，GPU在机器学习别广泛应用。算力得到很大提升。

**AlexNet** AlexNet使用了8层卷积神经网络，并以很大的有时赢得了ImageNet 2012图像识别挑战赛。证明了学习特征可以超越手工设计特征。

第一，其相比于LeNet，AlexNet包含8层变化，其中5层卷积核2层全连接隐藏层，以及一个全连接输出层。第一层的卷积窗口形状为11 ×11(应为图像的高宽为MNIST的10倍以上，需要较大的卷积窗口来捕捉物体)，第二层卷积窗口减小到5 ×5，之后全采用3 ×3。此外，第一、第二和第五个卷积层之后都在用了形状为3 ×3步幅为2的最大池化层，通道数在时LexNet的数10倍。紧接卷积层的时两个输出个数为4096的全连接层。有将近1GB的模型参数。

第二，使用了更加简单的ReLU激活函数。其计算更简单，且使得在不同的参数初始化方法下使模型的训练更加容易，其在正确建的梯度恒为1，二sigmoid输出在接近0或1时梯度几乎为0，容易在反向传播时无法更新部分模型参数。

第三，使用了丢弃法来控制全连接层的模型复杂度。

第四，引用了大量的图像增广，如翻转、剪裁、和颜色变化，从而进一步扩大数据集来缓解过拟合。

## 使用重复元素的网络(VGG)

**VGG块** 其组成规律是：连续使⽤数个相同的填充为1、窗口形状为3 × 3的卷积层后接上⼀个步幅为2、窗口形状为2 × 2的最⼤池化层。卷积层保持输⼊的⾼和宽不变，而池化层则对其减半。使用vgg_block函数来实现这个基础的GG块，可以指定卷积层的数量(num_convs)和输出通道数(num_channels)。

**VGG网络** 由卷积层模块后接全连接层模块构成。卷积层模块串联数个vgg_block,通过超参数conv_arch来指定每个VGG块里的卷积层个数和输出通道数。

**VGG-11** 有5个卷积块，前两个使用单卷积层，后3块使用双卷积层，第一块的输出通道是64，之后每次对输出通道翻倍，知道变为512。由于使用了8个卷个卷积层和3个全连接层，被称为VGG-11。

## 网络中的网络(NiN)

它与之前的三个网络思路不同，通过串联多个卷积层和“全连接层”构成的小网络来构建一个深层网络。

**NiN块** 卷积层的输入和输出通常是思维数组(样本,通道,高,宽)，而全连接层的输入输出则是二维样本(样本,特征)。他们之间的连接需要对样本进行维度转换。但是1×1卷积层可以当成全连接层使用，其空间维度(高和宽)上的每个元素相当于样本，通道相当于特征，NiN使用1×1卷积层来代替全连接层。从而使空间信息能够自然传递到后面的层中去。下图显示了两类网络的区别，左侧是AlexNet和VGG等，右侧是NiN。



![5_5](/5_5.png)

NiN块是NiN中的基础块。它由⼀个卷积层加两个充当全连接层的1 × 1卷积层串联而成。其中第⼀个卷积层的超参数可以⾃⾏设置，而第⼆和第三个卷积层的超参数⼀般是固定的。

```python
def nin_block(num_channels, kernel_size, strides, padding):
    blk = nn.Sequential()
    blk.add(nn.Conv2D(num_channels, kernel_size,strides, padding, activation='relu'),
        nn.Conv2D(num_channels, kernel_size=1, activation='relu'),
        nn.Conv2D(num_channels, kernel_size=1, activation='relu'))
    return blk
```

**NiN模型** 使用卷积窗口形状分别为11 × 11、5 × 5和3 × 3的卷积层，输出通道和AlexNet一致，每个NiN块后接一个步幅为2，窗口形状为3 × 3的最大池化层。

NiN去掉了AlexNet后的3个前连接层，使用了输出通道数等于标签类别墅的NiN块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类。全局平均池化层指窗口形状等于输入空间维度的平均池化层。能够限制减小模型参数尺寸从而缓解过拟合。

```python
net = nn.Sequential()
net.add(nin_block(96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2D(pool_size=3, strides=2),
    nin_block(256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2D(pool_size=3, strides=2),
    nin_block(384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2D(pool_size=3, strides=2), nn.Dropout(0.5),
    # 标签类别数是10
    nin_block(10, kernel_size=3, strides=1, padding=1),
    # 全局平均池化层将窗⼝形状⾃动设置成输⼊的⾼和宽
    nn.GlobalAvgPool2D(),
    # 将四维的输出转成⼆维的输出，其形状为(批量⼤⼩, 10)
    nn.Flatten())
```

## 含并行连接的网络(GoogLeNet)

**Inception块** 是GoogLeNet中的基础卷积块，其结构如下所示。

![5_6](/5_6.png)

中间2个线路会对输⼊先做1 × 1卷积来减少输⼊通道数，以降低模型复杂度。第四条线路则使⽤3×3最⼤池化层，后接1×1卷积层来改变通道数。4条线路都使⽤了合适的填充来使输⼊与输出的⾼和宽⼀致。最后我们将每条线路的输出在通道维上连结。其构造如下:

```python
class Inception(nn.Block):
    # c1 - c4为每条线路⾥的层的输出通道数
    def __init__(self, c1, c2, c3, c4, **kwargs):
        super(Inception, self).__init__(**kwargs)
        # 线路1，单1 x 1卷积层
        self.p1_1 = nn.Conv2D(c1, kernel_size=1, activation='relu')
        # 线路2，1 x 1卷积层后接3 x 3卷积层
        self.p2_1 = nn.Conv2D(c2[0], kernel_size=1, activation='relu')
        self.p2_2 = nn.Conv2D(c2[1], kernel_size=3, padding=1,activation='relu')
        # 线路3，1 x 1卷积层后接5 x 5卷积层
        self.p3_1 = nn.Conv2D(c3[0], kernel_size=1, activation='relu')
        self.p3_2 = nn.Conv2D(c3[1], kernel_size=5, padding=2,activation='relu')
        # 线路4，3 x 3最⼤池化层后接1 x 1卷积层
        self.p4_1 = nn.MaxPool2D(pool_size=3, strides=1, padding=1)
        self.p4_2 = nn.Conv2D(c4, kernel_size=1, activation='relu')

    def forward(self, x):
        p1 = self.p1_1(x)
        p2 = self.p2_2(self.p2_1(x))
        p3 = self.p3_2(self.p3_1(x))
        p4 = self.p4_2(self.p4_1(x))
        return nd.concat(p1, p2, p3, p4, dim=1) # 在通道维上连结输出
```

**GoogLeNet模型** 主体卷积部分使用5个模块，每个模块之间使用步幅为2的3×3最大池化层来减小输出高宽。

第一模块使用一个通道64的为7×7卷积层。 

第⼆模块使⽤2个卷积层：⾸先是64通道的1×1卷积层，然后是将通道增⼤3倍的3×3卷积层。它对应Inception块中的第⼆条线路。

第三模块串联2个完整的Inception块。第⼀个Inception块的输出通道数为64+128+32+32 = 256其中第2、3条线路先分别将输⼊通道数减小⾄96/192 = 1/2和16/192 = 1/12。第⼆个Inception块输出通道数增⾄128 + 192 + 96 + 64 = 480，其中第2,3条线路先分别将输⼊通道数减小⾄128/256 = 1/2和32/256 = 1/8。

第四模块更加复杂。它串联了5个Inception块，其输出通道数分别是192 + 208 + 48 + 64 = 512160+224+64+64 = 512、128+256+64+64 = 512、112+288+64+64 = 528和256+320+128+128 =832。这些线路的通道数分配和第三模块中的类似，⾸先含3 × 3卷积层的第⼆条线路输出最多通道，其次是仅含1×1卷积层的第⼀条线路，之后是含5×5卷积层的第三条线路和含3×3最⼤池化层的第四条线路。其中第⼆、第三条线路都会先按⽐例减小通道数。

## 批量归一化

批量归一化能让较深的神经网络的训练变得更加容易。之前进行过数据进行标准化处理，指任意一个特征在数据集中的所有样本上均值为0，标准差为1。当是对于深层的神经网络还不够。当层数较多时，当每层中的参数更新是，靠近输出层的输出容易出现剧烈变化，造成数值不稳定，难以训练有效的深度模型。批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在中间输出的数值更稳定。

**全连接层的批量归一化层** 通产将批量归一化层置于全连接层中的仿射变化和激活函数之间。设全连接层的输⼊为u，权重参数和偏差参数分别为W和b，激活函数为ϕ。BN表示归一化，使用批量归一化的全连接层输出入如下
$$
x = Wu + b\\
ϕ(BN(x))
$$
对于一个仿射变化输出的小批量B中的样本进行归一化输出维度不变，其计算如下
$$
y^{(i)} = BN(x^{(i)}),\\
$$
需要分别计算其均值，方差,ϵ > 0是⼀个很小的常数，保证分⺟⼤于0。
$$
\mu_B \leftarrow\frac{1}{m}\sum^m_{i=1}x_{(i)} ,\\
\sigma_B^2\leftarrow\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_B)^2\\
\hat{x}^{(i)}\leftarrow\frac{x^{(i)-\mu_B}}{\sqrt{\sigma_B^2+\epsilon}}
$$
批量归一化引入了两个可以学习的模型参数，拉伸γ和偏移β。按元素乘法（符号⊙），其使用如下
$$
y^{(i)} \leftarrow γ ⊙ \hat{x}^{(i)} + β
$$
可学习的拉伸和偏移参数保留了不对x (i) 做批量归⼀化的可能（将特征拉伸偏移为原来的值）。

**对卷积层做批量归一化** 发生在卷积计算之后，应用激活函数之前。如果有多个输出通道，需要分别做一次批量归一化，每个通道拥有独立的拉伸和偏移参数(标量)。在单个通道上，假设卷积计算输出的⾼和宽分别为p和q，需要对通道中的m×p×q个元素同事进行批量归一化，并使用其均值和方差。

**预测时的批量归一化** 使用归一化时，可以将批量大小设置得大一点，从而使批量内样本的均值和方差的计算较为准确。在使用预测好的模型进行预测是，为了任意输入有确定的输出，需要输出不依赖与小批量的样本均值和方差。因此需要通过移动平均估算整个训练集的样本均值和方差，并在预测时使用它们的到确定的输出。

使用NDArray实现的批量归一化层如下

```python
def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):
    # 通过autograd来判断当前模式是训练模式还是预测模式
    if not autograd.is_training():
    # 如果是在预测模式下，直接使⽤传⼊的移动平均所得的均值和⽅差
        X_hat = (X - moving_mean) / nd.sqrt(moving_var + eps)
    else:
        assert len(X.shape) in (2, 4)
        # 使⽤⼆维卷积层的情况，计算通道维上（axis=1）的均值和⽅差。这⾥我们需要保持
        # X的形状以便后⾯可以做⼴播运算
        mean = X.mean(axis=(0, 2, 3), keepdims=True)
        var = ((X - mean) ** 2).mean(axis=(0, 2, 3), keepdims=True)
    # 训练模式下⽤当前的均值和⽅差做标准化
    X_hat = (X - mean) / nd.sqrt(var + eps)
    # 更新移动平均的均值和⽅差
    moving_mean = momentum * moving_mean + (1.0 - momentum) * mean
    moving_var = momentum * moving_var + (1.0 - momentum) * var
Y = gamma * X_hat + beta # 拉伸和偏移
return Y, moving_mean, moving_var

class BatchNorm(nn.Block):
    #保存参与求梯度和迭代的拉伸参数gamma和偏移参数beta，同时也维护移动平均得到的均值和⽅差
    def __init__(self, num_features, num_dims, **kwargs):
        super(BatchNorm, self).__init__(**kwargs)
        if num_dims == 2:
            shape = (1, num_features)
        else:
            shape = (1, num_features, 1, 1)
        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成0和1
        self.gamma = self.params.get('gamma', shape=shape, init=init.One())
        self.beta = self.params.get('beta', shape=shape, init=init.Zero())
        # 不参与求梯度和迭代的变量，全在内存上初始化成0
        self.moving_mean = nd.zeros(shape)
        self.moving_var = nd.zeros(shape)

    def forward(self, X):
        # 如果X不在内存上，将moving_mean和moving_var复制到X所在显存上
        if self.moving_mean.context != X.context:
            self.moving_mean = self.moving_mean.copyto(X.context)
            self.moving_var = self.moving_var.copyto(X.context)
        # 保存更新过的moving_mean和moving_var
    Y, self.moving_mean, self.moving_var = batch_norm(X, self.gamma.data(), self.beta.data(), 
        self.moving_mean,self.moving_var, eps=1e-5, momentum=0.9)
    return Y
```



## 残差网络(ResNet)

对神经⽹络模型添加新的层来训练成恒等映射f(x)=x，理论上，原模型解的空间只是新模型解的空间的⼦空间，可能得出更优的解来拟合训练数据集。然而在实践中，添加过多的层后训练误差往往不降反升。即使利⽤批量归⼀化带来的数值稳定性使训练深层模型更加容易，该问题仍然存在。针对这一问题，出现了残差网络。

**残差块** 在神经网络的局部，假设我们希望学出的理想映射为f(x)，作图虚线框部分需要直接拟合出该映射，而右图的虚线框中的部分需要拟合出有关恒等映射的残差映射f(x)-x。残差映射在实际中通常更容易优化。残差映射也易于捕捉恒等映射的细微波动。右图为RestNet的基础快，即残差块。其输入可以通过跨层的数据线路更快的向前传播。

![5_7](/5_7.png)

ResNet沿⽤了VGG全3 × 3卷积层的设计。残差块⾥⾸先有2个有相同输出通道数的3 × 3卷积层。每个卷积层后接⼀个批量归⼀化层和ReLU激活函数。然后我们将输⼊跳过这两个卷积运算后直接加在最后的ReLU激活函数前。其实现如下:

```python
class Residual(nn.Block): # 本类已保存在d2lzh包中⽅便以后使⽤
    #可设定输出通道，是否使用而外1×1的卷积层和步幅的残差块
    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):
        super(Residual, self).__init__(**kwargs)
        #两层3×3的卷积层(高宽不变)
        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1,strides=strides)
        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2D(num_channels, kernel_size=1,strides=strides)
        else:
            self.conv3 = None
        #两层批量归一化
        self.bn1 = nn.BatchNorm()
        self.bn2 = nn.BatchNorm()

    def forward(self, X):
        #卷积层批量归一化交替串联
        Y = nd.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        return nd.relu(Y + X)
```

**ResNet模型** 其模型前2层和GoogLeNet相同:在输出通道数为64，步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。不同之处在于RestNet每个卷积层后增加的批量归一化层。

之后再接由4个残差块组成的模块，每个模块的残差块输出通道相同。由于模型的前两层使用了步幅为2的最大池化层，对高宽减半了，对第一个模块不需要在操作，之后的三个模块需要对模块中的第一个残差块里将上一个模块的输出通道翻倍，并高宽减半。

```python
def resnet_block(num_channels, num_residuals, first_block=False):
    #残差模块
    blk = nn.Sequential()
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.add(Residual(num_channels, use_1x1conv=True, strides=2))
        else:
            blk.add(Residual(num_channels))
    return blk

#模型的前两层
net = nn.Sequential()
net.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3),
    nn.BatchNorm(), nn.Activation('relu'),
    nn.MaxPool2D(pool_size=3, strides=2, padding=1))
#加入四个模块，每个模块使用两个残差块
net.add(resnet_block(64, 2, first_block=True),
    resnet_block(128, 2),
    resnet_block(256, 2),
    resnet_block(512, 2))
#加入全军平均池化层后接上全连接层输出
net.add(nn.GlobalAvgPool2D(), nn.Dense(10))
```

每个模块有4个卷积层，加上开始的卷积层和最后的全连接层，共18层，因此该模型也被称为RestNet-18。

## 稠密连接网络(DenseNet)

稠密连接网络与ResNet网络的对比如下，左侧的时ResNet,右侧的时DenseNet

![5_8](/5_8.png)

ResNet是将模块B和模块A的输出相加，而稠DenseNet是将模块A和模块B在通道维上想连接。DenseNet的主要构件模块是稠密快和过渡层，前者定义了输入和输出的连接，后者负责控制通道数，使之不过大。

**稠密块** 

其使用了ResNet改良版的“批量归一化、激活和卷积”结构，稠密块有多个这个结构构成，每个结构使用相同的输出通道数，在前向计算式将每块的输入和输出在通道维上相连接作为输出。

```python
def conv_block(num_channels):
    #改良的卷积结构
    blk = nn.Sequential()
    blk.add(nn.BatchNorm(), nn.Activation('relu'),
    nn.Conv2D(num_channels, kernel_size=3, padding=1))
    return bl

class DenseBlock(nn.Block):
    #稠密块，可以设置输出的通道数，和使用的卷积层数目
    def __init__(self, num_convs, num_channels, **kwargs):
        super(DenseBlock, self).__init__(**kwargs)
        self.net = nn.Sequential()
        for _ in range(num_convs):#每个卷积层的出处通道数相同
            self.net.add(conv_block(num_channels))

    def forward(self, X):
        for blk in self.net:
            Y = blk(X)
            X = nd.conum_channels, growth_rate = 64, 32 # num_channels为当前的通道数
num_convs_in_dense_blocks = [4, 4, 4, 4]
for i, num_convs in enumerate(num_convs_in_dense_blocks):
    net.add(DenseBlock(num_convs, growth_rate))
    # 上⼀个稠密块的输出通道数
    num_channels += num_convs * growth_rate
    # 在稠密块之间（非最后一层）加⼊通道数减半的过渡层
    if i != len(num_convs_in_dense_blocks) - 1:
        num_channels //= 2
        net.add(transition_block(num_channels))
#接上全局池化层和全连接层来输出
net.add(nn.BatchNorm(), nn.Activation('relu'), nn.GlobalAvgPool2D(),nn.Dense(10))ncat(X, Y, dim=1) #在通道维上将输⼊和输出连结
        return X
```

我们定义⼀个有2个输出通道数为10的卷积块。使⽤通道数为3的输⼊时，我们会得到通道数为3 + 2 × 10 = 23的输出。卷积块的通道数影响输出的通道数的增长，因此被称为增长率。

**过渡层** 由于稠密块会是通道数一直增加，是模型过于复杂，因此需要过渡层来控制模型复杂度。它通过1×1卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽，进一步降低模型的复杂度。

```python
def transition_block(num_channels):
    #过渡层
    blk = nn.Sequential()
    blk.add(nn.BatchNorm(), nn.Activation('relu'),
        nn.Conv2D(num_channels, kernel_size=1),
        nn.AvgPool2D(pool_size=2, strides=2))
    return blk
```

**DenseNet模型** 先使用和ResNet相同的单卷积层和最大池化层，输出通道数为64，步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。。

在连接4个稠密块，可以设置每个稠密块使用多少个卷积层，和卷积层输出通道数(增长率),这里设置卷积层数目为4，输出通道数为32，因此每个稠密块将增加128个通道。

使用过渡层来减半高和宽，并减半通道数。

```python
num_channels, growth_rate = 64, 32 # num_channels为当前的通道数
num_convs_in_dense_blocks = [4, 4, 4, 4]
for i, num_convs in enumerate(num_convs_in_dense_blocks):
    net.add(DenseBlock(num_convs, growth_rate))
    # 上⼀个稠密块的输出通道数
    num_channels += num_convs * growth_rate
    # 在稠密块之间（非最后一层）加⼊通道数减半的过渡层
    if i != len(num_convs_in_dense_blocks) - 1:
        num_channels //= 2
        net.add(transition_block(num_channels))
#接上全局池化层和全连接层来输出
net.add(nn.BatchNorm(), nn.Activation('relu'), nn.GlobalAvgPool2D(),nn.Dense(10))
```

