{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "%matplotlib inline\n",
    "'''\n",
    "现在的目录结构是：\n",
    "d2lzh包\n",
    "        chapter 2\n",
    "        chapter 3\n",
    "我要在chapter 3中导入d2lzh（在上一级目录中）就需要告诉python，导包时，同时扫描上一级目录\n",
    "因此要在路径中加上上一次层\n",
    "''' \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取和读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义和初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加一个输出个数为10的全连接层\n",
    "# 使用均值为0,标准差为0.01的正态分布随机初始化模型的权重参数\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sequential in module mxnet.gluon.nn.basic_layers:\n",
      "\n",
      "class Sequential(mxnet.gluon.block.Block)\n",
      " |  Stacks Blocks sequentially.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      net = nn.Sequential()\n",
      " |      # use net's name_scope to give child Blocks appropriate names.\n",
      " |      with net.name_scope():\n",
      " |          net.add(nn.Dense(10, activation='relu'))\n",
      " |          net.add(nn.Dense(20))\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      mxnet.gluon.block.Block\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __init__(self, prefix=None, params=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add(self, *blocks)\n",
      " |      Adds block on top of the stack.\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      Overrides to implement forward computation using :py:class:`NDArray`. Only\n",
      " |      accepts positional arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : list of NDArray\n",
      " |          Input tensors.\n",
      " |  \n",
      " |  hybridize(self, active=True, **kwargs)\n",
      " |      Activates or deactivates `HybridBlock` s recursively. Has no effect on\n",
      " |      non-hybrid children.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      active : bool, default True\n",
      " |          Whether to turn hybrid on or off.\n",
      " |      **kwargs : string\n",
      " |          Additional flags for hybridized operator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from mxnet.gluon.block.Block:\n",
      " |  \n",
      " |  __call__(self, *args)\n",
      " |      Calls forward. Only accepts positional arguments.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Registers parameters.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every child block as well as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fn : callable\n",
      " |          Function to be applied to each submodule, of form `fn(block)`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      this block\n",
      " |  \n",
      " |  cast(self, dtype)\n",
      " |      Cast this Block to use another data type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype\n",
      " |          The new data type.\n",
      " |  \n",
      " |  collect_params(self, select=None)\n",
      " |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      " |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      " |      which match some given regular expressions.\n",
      " |      \n",
      " |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      " |      'fc_bias']::\n",
      " |      \n",
      " |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      " |      \n",
      " |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      " |      using regular expressions::\n",
      " |      \n",
      " |          model.collect_params('.*weight|.*bias')\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      select : str\n",
      " |          regular expressions\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The selected :py:class:`ParameterDict`\n",
      " |  \n",
      " |  initialize(self, init=<mxnet.initializer.Uniform object at 0x7fcb58d6b3c8>, ctx=None, verbose=False, force_reinit=False)\n",
      " |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      " |      Equivalent to ``block.collect_params().initialize(...)``\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      init : Initializer\n",
      " |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      " |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      " |      ctx : Context or list of Context\n",
      " |          Keeps a copy of Parameters on one or many context(s).\n",
      " |      verbose : bool, default False\n",
      " |          Whether to verbosely print out details on initialization.\n",
      " |      force_reinit : bool, default False\n",
      " |          Whether to force re-initialization if parameter is already initialized.\n",
      " |  \n",
      " |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False, cast_dtype=False, dtype_source='current')\n",
      " |      Load parameters from file previously saved by `save_parameters`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : str\n",
      " |          Path to parameter file.\n",
      " |      ctx : Context or list of Context, default cpu()\n",
      " |          Context(s) to initialize loaded parameters on.\n",
      " |      allow_missing : bool, default False\n",
      " |          Whether to silently skip loading parameters not represents in the file.\n",
      " |      ignore_extra : bool, default False\n",
      " |          Whether to silently ignore parameters from the file that are not\n",
      " |          present in this Block.\n",
      " |      cast_dtype : bool, default False\n",
      " |          Cast the data type of the NDArray loaded from the checkpoint to the dtype\n",
      " |          provided by the Parameter if any.\n",
      " |      dtype_source : str, default 'current'\n",
      " |          must be in {'current', 'saved'}\n",
      " |          Only valid if cast_dtype=True, specify the source of the dtype for casting\n",
      " |          the parameters\n",
      " |      References\n",
      " |      ----------\n",
      " |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      " |  \n",
      " |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      " |      [Deprecated] Please use load_parameters.\n",
      " |      \n",
      " |      Load parameters from file.\n",
      " |      \n",
      " |      filename : str\n",
      " |          Path to parameter file.\n",
      " |      ctx : Context or list of Context, default cpu()\n",
      " |          Context(s) to initialize loaded parameters on.\n",
      " |      allow_missing : bool, default False\n",
      " |          Whether to silently skip loading parameters not represents in the file.\n",
      " |      ignore_extra : bool, default False\n",
      " |          Whether to silently ignore parameters from the file that are not\n",
      " |          present in this Block.\n",
      " |  \n",
      " |  name_scope(self)\n",
      " |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      " |      names. Should be used within a ``with`` statement::\n",
      " |      \n",
      " |          with self.name_scope():\n",
      " |              self.dense = nn.Dense(20)\n",
      " |      \n",
      " |      Please refer to\n",
      " |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      " |      for more info on prefix and naming.\n",
      " |  \n",
      " |  register_child(self, block, name=None)\n",
      " |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      " |      attributes will be registered automatically.\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the block.\n",
      " |      \n",
      " |      The hook function is called immediately after :func:`forward`.\n",
      " |      It should not modify the input or output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      hook : callable\n",
      " |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`mxnet.gluon.utils.HookHandle`\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the block.\n",
      " |      \n",
      " |      The hook function is called immediately before :func:`forward`.\n",
      " |      It should not modify the input or output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      hook : callable\n",
      " |          The forward hook function of form `hook(block, input) -> None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`mxnet.gluon.utils.HookHandle`\n",
      " |  \n",
      " |  save_parameters(self, filename)\n",
      " |      Save parameters to file.\n",
      " |      \n",
      " |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      " |      method only saves parameters, not model structure. If you want to save\n",
      " |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : str\n",
      " |          Path to file.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      " |  \n",
      " |  save_params(self, filename)\n",
      " |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      " |      from SymbolBlock later, please use export instead.\n",
      " |      \n",
      " |      Save parameters to file.\n",
      " |      \n",
      " |      filename : str\n",
      " |          Path to file.\n",
      " |  \n",
      " |  summary(self, *inputs)\n",
      " |      Print the summary of the model's output and parameters.\n",
      " |      \n",
      " |      The network must have been initialized, and must not have been hybridized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      inputs : object\n",
      " |          Any input that the model supports. For any tensor in the input, only\n",
      " |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  name\n",
      " |      Name of this :py:class:`Block`, without '_' in the end.\n",
      " |  \n",
      " |  params\n",
      " |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      " |      children's parameters).\n",
      " |  \n",
      " |  prefix\n",
      " |      Prefix of this :py:class:`Block`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax的交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gloss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7884, train acc 0.747, test acc 0.803\n",
      "epoch 2, loss 0.5741, train acc 0.810, test acc 0.825\n",
      "epoch 3, loss 0.5290, train acc 0.824, test acc 0.826\n",
      "epoch 4, loss 0.5042, train acc 0.831, test acc 0.838\n",
      "epoch 5, loss 0.4891, train acc 0.835, test acc 0.839\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "- 用mxnet中的Gluon所提供的函数具有更好的稳定性。\n",
    "- 使用Gluon实现Softmax回归的步骤\n",
    "    - 获取数据\n",
    "    - 定义模型\n",
    "    - 定义交叉熵损失函数\n",
    "    - 定义优化算法（训练算法）\n",
    "    - 训练模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
