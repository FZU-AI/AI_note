{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本节讨论深度学习模型中数据稳定性问题以及模型参数的初始化方法.\n",
    "- 深度模型有关数值稳定性的经典问题就是衰减(vanishing)和爆炸(explosion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.15.1 衰减和爆炸\n",
    "- 当神经网络的层数较多时，模型的数值稳定性容易变差。假设一个层数为L的多层感知机的第l层$H^{(l)}$的权重参数为$H^{(l)}$，输出层$H^{(L)}$的权重参数为$H^{(L)}$。为了方便讨论，不考虑偏差参数，且设所有隐藏层的激活函数为恒等映射(indentity mapping)。\n",
    "$\\phi(x) = x$，其实就是没有激活函数。给定输入$X$，多层感知机的第l层的输出$H^{(l)} = XW^{(1)}W^{(2)}...W^{(l)}$。此时，如果层数l较大，$H^{(l)}$的计算可能会出现衰减或爆炸。举个例子，假设输入和所有层的权重参数都是标量，如权重参数为0.2和5，多层感知机的第30层输出为输入$X$分别与$0.2^{30}\\approx 1 * 10^{-21}(衰减) 和 5^30 \\approx 10^20$(爆炸)的乘积。从这个例子可以看出，当层数太多的时候，会出现衰减和爆炸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.15.2 随机初始化模型参数\n",
    "- 为何要随机初始化模型参数\n",
    "    - 如果不采用随机初始化，那么无论隐藏单元有多少层，其实都想当于1层，因为每一次的参数都相同\n",
    "- MXNet的随机初始化\n",
    "    - net.initialize(init.Normal(sigma=0.01))使模型net的权重参数惨用正态分布的随机初始化方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小结\n",
    "- 深度模型有关数值稳定性的典型问题是衰减和爆炸。当神经网络的层数较多时，模型的数值稳定性容易变差。\n",
    "- 我们通常需要随机初始化神经网络的模型参数，如权重参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
