{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import init, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='relu'))\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize()     #使用默认初始化方式\n",
    "\n",
    "X = nd.random.uniform(shape=(2, 20))\n",
    "Y = net(X) # 前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dense8_ (\n",
       "   Parameter dense8_weight (shape=(256, 20), dtype=float32)\n",
       "   Parameter dense8_bias (shape=(256,), dtype=float32)\n",
       " ), mxnet.gluon.parameter.ParameterDict)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params, type(net[0].params) # 通过方括号[]来访问网络的任一层，索引0表⽰隐藏层为Sequential实例最先添加的层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter dense8_weight (shape=(256, 20), dtype=float32),\n",
       " Parameter dense8_weight (shape=(256, 20), dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params['dense8_weight'], net[0].weight # 使用名字或者变量明来访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.06700657 -0.00369488  0.0418822  ... -0.05517294 -0.01194733\n",
       "  -0.00369594]\n",
       " [-0.03296221 -0.04391347  0.03839272 ...  0.05636378  0.02545484\n",
       "  -0.007007  ]\n",
       " [-0.0196689   0.01582889 -0.00881553 ...  0.01509629 -0.01908049\n",
       "  -0.02449339]\n",
       " ...\n",
       " [ 0.00010955  0.0439323  -0.04911506 ...  0.06975312  0.0449558\n",
       "  -0.03283203]\n",
       " [ 0.04106557  0.05671307 -0.00066976 ...  0.06387014 -0.01292654\n",
       "   0.00974177]\n",
       " [ 0.00297424 -0.0281784  -0.06881659 ... -0.04047417  0.00457048\n",
       "   0.05696651]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data() # 分别通过data函数访问参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " ...\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grad函数来访问其梯度\n",
    "# 还没有进行反向传播计算，所以梯度的值全为0\n",
    "net[0].weight.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 10 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#访问输出层的偏差值\n",
    "net[1].bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential4_ (\n",
       "  Parameter dense8_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense8_bias (shape=(256,), dtype=float32)\n",
       "  Parameter dense9_weight (shape=(10, 256), dtype=float32)\n",
       "  Parameter dense9_bias (shape=(10,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取net变量所有嵌套（例如通过add函数嵌套）的层所包含的所有参数。同样是参数名到参数实例的字典\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential4_ (\n",
       "  Parameter dense8_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense9_weight (shape=(10, 256), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#利用正则表达式来匹配参数名，进行筛选\n",
    "net.collect_params('.*weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 0.00841876 -0.01005536  0.03132214 -0.00435899 -0.00492951  0.01437187\n",
       " -0.00318141 -0.00162825  0.0068361   0.01610669 -0.01264223  0.00138954\n",
       "  0.00667116  0.00214447  0.00993847  0.00108742  0.00535343 -0.0186105\n",
       " -0.00468956 -0.0067683 ]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非首次对模型初始化需要指定force_reinit为真\n",
    "net.initialize(init=init.Normal(sigma=0.01), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用常数来初始化权重参数\n",
    "net.initialize(init=init.Constant(1), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense2_weight (256, 20)\n",
      "Init dense3_weight (10, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 6.3104763 -8.299978  -6.8117104 -8.110842   0.         0.\n",
       " -0.         8.98595   -8.745741   8.73493   -0.        -0.\n",
       " -0.         0.         6.9807663  0.        -9.333907  -0.\n",
       "  9.179653  -7.6045732]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自定义初试化方法\n",
    "class MyInit(init.Initializer):\n",
    "    #自定义权重的初始化方法\n",
    "    def _init_weight(self, name, data):\n",
    "        print('Init', name, data.shape)\n",
    "        data[:] = nd.random.uniform(low=-10, high=10, shape=data.shape)\n",
    "        # 绝对值小于5的设置为0，大于5的保持不变\n",
    "        data *= data.abs() >= 5\n",
    "\n",
    "net.initialize(MyInit(), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 7.3104763 -7.2999783 -5.8117104 -7.1108418  1.         1.\n",
       "  1.         9.98595   -7.745741   9.73493    1.         1.\n",
       "  1.         1.         7.9807663  1.        -8.333907   1.\n",
       " 10.179653  -6.6045732]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接设置权重在现有基础上+1\n",
    "net[0].weight.set_data(net[0].weight.data() + 1)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 8 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "shared = nn.Dense(8, activation='relu')\n",
    "# 我们让模型的第二隐藏层（shared变量）和第三隐藏层共享模型参数。\n",
    "net.add(nn.Dense(8, activation='relu'),\n",
    "        shared,\n",
    "        nn.Dense(8, activation='relu', params=shared.params),\n",
    "        nn.Dense(10))\n",
    "net.initialize()\n",
    "\n",
    "X = nd.random.uniform(shape=(2, 20))\n",
    "net(X)\n",
    "\n",
    "net[1].weight.data()[0] == net[2].weight.data()[0]\n",
    "# # 在反向传播计算时，第二隐藏层和第三隐藏层的梯度都会被累加在shared.params.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
