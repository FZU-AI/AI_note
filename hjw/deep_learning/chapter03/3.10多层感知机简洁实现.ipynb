{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "# 添加隐藏层\n",
    "net.add(nn.Dense(256, activation='relu'), nn.Dense(10))     #以relu函数作为激活函数\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.8025, train acc 0.697, test acc 0.798\n",
      "epoch 2, loss 0.4845, train acc 0.821, test acc 0.854\n",
      "epoch 3, loss 0.4319, train acc 0.840, test acc 0.848\n",
      "epoch 4, loss 0.3955, train acc 0.854, test acc 0.863\n",
      "epoch 5, loss 0.3724, train acc 0.862, test acc 0.869\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)    #获取数据\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()                  #损失函数\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "num_epochs = 5                                          #迭代周期\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 3.8723, train acc 0.563, test acc 0.680\n",
      "epoch 2, loss 0.8627, train acc 0.757, test acc 0.824\n",
      "epoch 3, loss 0.6374, train acc 0.796, test acc 0.848\n",
      "epoch 4, loss 0.5457, train acc 0.816, test acc 0.806\n",
      "epoch 5, loss 0.5002, train acc 0.828, test acc 0.854\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "# 尝试使用tanh函数作为激活函数\n",
    "net.add(nn.Dense(256, activation='tanh'),\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.0541, train acc 0.609, test acc 0.731\n",
      "epoch 2, loss 0.5779, train acc 0.783, test acc 0.808\n",
      "epoch 3, loss 0.5039, train acc 0.816, test acc 0.835\n",
      "epoch 4, loss 0.4681, train acc 0.830, test acc 0.843\n",
      "epoch 5, loss 0.4431, train acc 0.839, test acc 0.846\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "# 尝试使用sigmoid函数作为激活函数\n",
    "net.add(nn.Dense(256, activation='sigmoid'),\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
