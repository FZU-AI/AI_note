{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的包或模块\n",
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import loss as gloss\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9.1 获取和读取数据 \n",
    "batch_size=256\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9.2 定义模型参数\n",
    "# 输入个数，输出个数，隐藏单元个数\n",
    "num_inputs,num_outputs,num_hiddens =784,10,256\n",
    "\n",
    "W1=nd.random.normal(scale=0.01,shape=(num_inputs,num_hiddens))\n",
    "b1=nd.zeros(num_hiddens)\n",
    "W2=nd.random.normal(scale=0.01,shape=(num_hiddens,num_outputs))\n",
    "b2=nd.zeros(num_outputs)\n",
    "params =[W1,b1,W2,b2]\n",
    "# 为w,b申请梯度的内存\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9.3 定义激活函数\n",
    "def relu(X):\n",
    "    return nd.maximum(X,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9.4 定义模型\n",
    "def net(X):\n",
    "    X=X.reshape((-1,num_inputs))# X.reshape为 样本数x784\n",
    "    H=relu(nd.dot(X,W1)+b1)# W1为784x256\n",
    "    return nd.dot(H,W2)+b2# W2为256x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9.5 定义损失函数 \n",
    "# 为了得到更好的数值稳定性，我们直接使⽤Gluon提供的包括softmax运算和交叉熵损失计算的 函数。 \n",
    "loss=gloss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9.6 训练模型 \n",
    "#start=time.time()\n",
    "num_epochs,lr =5,0.5\n",
    "#d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)\n",
    "#time=time.time()-start\n",
    "#time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.1145, train acc 0.564, test acc 0.787\n",
      "epoch 2, loss 0.7082, train acc 0.746, test acc 0.824\n",
      "epoch 3, loss 0.4766, train acc 0.823, test acc 0.845\n",
      "epoch 4, loss 0.4316, train acc 0.841, test acc 0.859\n",
      "epoch 5, loss 0.3996, train acc 0.850, test acc 0.854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39.58924889564514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 练习2 试着加⼊⼀个新的隐藏层，看看对实验结果有什么影响。 \n",
    "# 输入个数，输出个数，隐藏单元个数\n",
    "num_inputs,num_outputs,num_hiddens1,num_hiddens2 =784,10,256,256\n",
    "\n",
    "W1=nd.random.normal(scale=0.01,shape=(num_inputs,num_hiddens1))\n",
    "b1=nd.zeros(num_hiddens1)\n",
    "W2=nd.random.normal(scale=0.01,shape=(num_hiddens1,num_hiddens2))\n",
    "b2=nd.zeros(num_hiddens2)\n",
    "W3=nd.random.normal(scale=0.01,shape=(num_hiddens2,num_outputs))\n",
    "b3=nd.zeros(num_outputs)\n",
    "params =[W1,b1,W2,b2,W3,b3]\n",
    "# w,b申请梯度的内存\n",
    "for param in params:\n",
    "    param.attach_grad()\n",
    "\n",
    "def net(X):\n",
    "    X=X.reshape((-1,num_inputs))# X.reshape为 样本数x784\n",
    "    H1=relu(nd.dot(X,W1)+b1)# W1为784x256\n",
    "    H2=relu(nd.dot(H1,W2)+b2)\n",
    "    return nd.dot(H2,W3)+b3# W2为256x10\n",
    "\n",
    "start=time.time()\n",
    "num_epochs,lr =5,0.5\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)\n",
    "time=time.time()-start\n",
    "time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
