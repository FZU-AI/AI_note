{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cpu(1), gpu(0), gpu(1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.6.1 计算设备\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "# mx.cpu()表⽰所有的物理CPU和内存。\n",
    "# mx.gpu()只代表⼀块GPU和相应的显存。\n",
    "mx.cpu(1),mx.gpu(),mx.gpu(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @cpu(0)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.6.2 NDArray的GPU计算 \n",
    "# 在默认情况下，NDArray存在内存上。\n",
    "x=nd.array([1,2,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpu(0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过NDArray的context属性来查看该NDArray所在的设备。 \n",
    "x.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU上的存储 \n",
    "# 1.在创建NDArray的时候通过ctx参数指定存储设备。\n",
    "a=nd.array([1,2,3],ctx=mx.gpu())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.6686509  0.17409194 0.3850025 ]\n",
       " [0.24678314 0.35134333 0.8404298 ]]\n",
       "<NDArray 2x3 @gpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=nd.random.uniform(shape=(2,3),ctx=mx.gpu())\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.通过copyto函数和as_in_context函数在设备之间传输数据。 \n",
    "# 将内存上的NDArray变量x复制到gpu(0)上。 x->gpu\n",
    "y=x.copyto(mx.gpu())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [1. 1. 1.]\n",
       " <NDArray 3 @cpu(0)>,\n",
       " \n",
       " [1. 1. 1.]\n",
       " <NDArray 3 @cpu(0)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=nd.array([1,1,1])\n",
    "n=nd.array([1,2,3])\n",
    "# copyto还可以复制NDArray变量m复制到NDArray变量n上(m->n),但m，n形状必须相同\n",
    "t=m.copyto(n)\n",
    "t,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=x.as_in_context(mx.gpu())\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果源变量和⽬标变量的context⼀致，as_in_context函数使⽬标变量和源变量共享源变量的内存或显存。 \n",
    "y.as_in_context(mx.gpu()) is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 而copyto函数总是为⽬标变量开新的内存或显存。 \n",
    "y.copyto(mx.gpu()) is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 20.085537 109.1963   445.2395  ]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU上的计算 \n",
    "# MXNet的计算会在数据的context属性所指定的设备上执⾏。\n",
    "# 为了使⽤GPU计算，我们只需要事先将数据存储在显存上。计算结果会⾃动保存在同⼀块显卡的显存上。 \n",
    "(z+2).exp()*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MXNet要求计算的所有输⼊数据都在内存或同⼀块显卡的显存上。\n",
    "# 这样设计的原因是CPU和不同的GPU之间的数据交互通常⽐较耗时。\n",
    "# x*y\n",
    "# 当我们打印NDArray或将NDArray转换成NumPy格式时，如果数据不在内存⾥，\n",
    "# MXNet会将它先复制到内存，从而造成额外的传输开销。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6.3 Gluon的GPU计算\n",
    "# Gluon的模型可以在初始化时通过ctx参数指定设备\n",
    "net=nn.Sequential()\n",
    "net.add(nn.Dense(1))\n",
    "net.initialize(ctx=mx.gpu())# 将模型参数初始化在显存上。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.0068339 ]\n",
       " [0.01366779]\n",
       " [0.02050169]]\n",
       "<NDArray 3x1 @gpu(0)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当输⼊是显存上的NDArray时，Gluon会在同⼀块显卡的显存上计算结果。 \n",
    "net(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.0068339]]\n",
       "<NDArray 1x1 @gpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mx.gpu??\n",
    "mx.cpu??\n",
    "mx.gpu??\n",
    "\n",
    "\n",
    "\n",
    "x.as_in_context??\n",
    "x.copyto??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
