{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.1简单例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 导入autograd库\n",
    "from mxnet import autograd,nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.]\n",
       " [1.]\n",
       " [2.]\n",
       " [3.]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x为n维列向量\n",
    "x=nd.arange(4).reshape((4,1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 调用attach_grad()函数来申请存储梯度所需要的内存,标记需要求梯度的参数x\n",
    "x.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[28.]]\n",
       "<NDArray 1x1 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. 调用autograd.record()记录求梯度的计算,x的形状为（4,1）, y是一个标量\n",
    "with autograd.record():\n",
    "    y=2*nd.dot(x.T,x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 调用backward()函数自动求梯度,对y求关于x的梯度\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.]\n",
       " [ 4.]\n",
       " [ 8.]\n",
       " [12.]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  x的梯度,函数y = 2(x^⊤)x关于x的梯度应为4x\n",
    "assert (x.grad-4*x).norm().asscalar() ==0\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.2 训练模式和预测模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#调用record函数后，MXNet会记录并计算梯度。此外，默认情况下autograd还会将运⾏模式从预测模式转为训练模式。\n",
    "print(autograd.is_training())\n",
    "with autograd.record():\n",
    "    print(autograd.is_training())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.3 对Python控制流求梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2 \n",
    "    while b.norm().asscalar() < 1000:\n",
    "        b = b * 2 \n",
    "    if b.sum().asscalar() > 0:\n",
    "        c = b \n",
    "    else: \n",
    "        c = 100 * b\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.1630785]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.random.normal(shape=(1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1190.9924]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    c=f(a)\n",
    "c.backward()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[01:58:47] C:\\Jenkins\\workspace\\mxnet-tag\\mxnet\\src\\imperative\\imperative.cc:295: Check failed: !AGInfo::IsNone(*i): Cannot differentiate node because it is not in a computational graph. You need to set is_recording to true or use autograd.record() to save computational graphs for backward. If you want to differentiate the same graph twice, you need to pass retain_graph=True to backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c64e6f25b1ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\miniconda3\\envs\\gluon\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[0;32m   2837\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2838\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2839\u001b[1;33m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[0;32m   2840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2841\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\gluon\\lib\\site-packages\\mxnet\\base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \"\"\"\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMXNetError\u001b[0m: [01:58:47] C:\\Jenkins\\workspace\\mxnet-tag\\mxnet\\src\\imperative\\imperative.cc:295: Check failed: !AGInfo::IsNone(*i): Cannot differentiate node because it is not in a computational graph. You need to set is_recording to true or use autograd.record() to save computational graphs for backward. If you want to differentiate the same graph twice, you need to pass retain_graph=True to backward."
     ]
    }
   ],
   "source": [
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad==c/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NDArray', '_Null', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_internal', '_random_helper', 'current_context', 'exponential', 'exponential_like', 'gamma', 'gamma_like', 'generalized_negative_binomial', 'generalized_negative_binomial_like', 'multinomial', 'negative_binomial', 'negative_binomial_like', 'normal', 'normal_like', 'numeric_types', 'poisson', 'poisson_like', 'randint', 'randn', 'shuffle', 'uniform', 'uniform_like']\n"
     ]
    }
   ],
   "source": [
    "print(dir(nd.random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function uniform in module mxnet.ndarray.random:\n",
      "\n",
      "uniform(low=0, high=1, shape=_Null, dtype=_Null, ctx=None, out=None, **kwargs)\n",
      "    Draw random samples from a uniform distribution.\n",
      "    \n",
      "    Samples are uniformly distributed over the half-open interval *[low, high)*\n",
      "    (includes *low*, but excludes *high*).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    low : float or NDArray, optional\n",
      "        Lower boundary of the output interval. All values generated will be\n",
      "        greater than or equal to low. The default value is 0.\n",
      "    high : float or NDArray, optional\n",
      "        Upper boundary of the output interval. All values generated will be\n",
      "        less than high. The default value is 1.0.\n",
      "    shape : int or tuple of ints, optional\n",
      "        The number of samples to draw. If shape is, e.g., `(m, n)` and `low` and\n",
      "        `high` are scalars, output shape will be `(m, n)`. If `low` and `high`\n",
      "        are NDArrays with shape, e.g., `(x, y)`, then output will have shape\n",
      "        `(x, y, m, n)`, where `m*n` samples are drawn for each `[low, high)` pair.\n",
      "    dtype : {'float16', 'float32', 'float64'}, optional\n",
      "        Data type of output samples. Default is 'float32'\n",
      "    ctx : Context, optional\n",
      "        Device context of output. Default is current context. Overridden by\n",
      "        `low.context` when `low` is an NDArray.\n",
      "    out : NDArray, optional\n",
      "        Store output to an existing NDArray.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    NDArray\n",
      "        An NDArray of type `dtype`. If input `shape` has shape, e.g.,\n",
      "        `(m, n)` and `low` and `high` are scalars, output shape will be `(m, n)`.\n",
      "        If `low` and `high` are NDArrays with shape, e.g., `(x, y)`, then the\n",
      "        return NDArray will have shape `(x, y, m, n)`, where `m*n` uniformly distributed\n",
      "        samples are drawn for each `[low, high)` pair.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> mx.nd.random.uniform(0, 1)\n",
      "    [ 0.54881352]\n",
      "    <NDArray 1 @cpu(0)\n",
      "    >>> mx.nd.random.uniform(0, 1, ctx=mx.gpu(0))\n",
      "    [ 0.92514056]\n",
      "    <NDArray 1 @gpu(0)>\n",
      "    >>> mx.nd.random.uniform(-1, 1, shape=(2,))\n",
      "    [ 0.71589124  0.08976638]\n",
      "    <NDArray 2 @cpu(0)>\n",
      "    >>> low = mx.nd.array([1,2,3])\n",
      "    >>> high = mx.nd.array([2,3,4])\n",
      "    >>> mx.nd.random.uniform(low, high, shape=2)\n",
      "    [[ 1.78653979  1.93707538]\n",
      "     [ 2.01311183  2.37081361]\n",
      "     [ 3.30491424  3.69977832]]\n",
      "    <NDArray 3x2 @cpu(0)>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nd.random. uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.random.uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.random.uniform??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
